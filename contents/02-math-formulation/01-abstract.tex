\section{Математическая постановка задачи}

Пусть $T = \{t_1, t_2, \ldots , t_k\}$ --- множество экземпляров сетевой активности. Каждому из объектов данного множества по формуле (\ref{X_def}) поставим в соответствие \textit{признаковое описание}, полученное биекцией $\xi: T \rightarrow X, \ |T| = |X| = k$.

\begin{equation}\label{X_def}
    X = \{\overline{x_i} = \xi(t_i)\ |\ \forall t_i \in T\} = \{\overline{x_1}, \overline{x_2}, \ldots , \overline{x_k}\},
\end{equation}
где каждый вектор $\overline{x_i},\ i = \overline{1,k}$ представляет собой набор характеристик, которые достаточно полно описывают соответствующий экземпляр $t_i$ в рамках данной задачи.

Также соотношением (\ref{Y_def}) определим множество меток классов принадлежности экземпляров из $T$ к аномальному трафику:
\begin{equation}\label{Y_def}
    Y = \{y_1,\ y_2\},
\end{equation}
где    $y_1$ --- метка класса аномальных экземпляров (или <<аномальные>>); \\
$y_2$ --- метка класса экземпляров без аномалий (или <<нормальные>>).

По формуле (\ref{f_def}) кусочно зададим функцию принятия решений $f$, которая для каждого экземпляра $t_i \in T$ на основе соответствующего вектора признаков $\overline{x_i} \in X$, однозначно позволяет определить метку класса из $Y$:

\begin{equation}\label{f_def}
    f(\overline{x_i}) = \begin{cases}
            \ \ 1, &\ \text{если } \overline{x_i} \text{ соответствует классу }y_1, \\
               -1, &\ \text{если } \overline{x_i} \text{ соответствует классу }y_2, \\ 
         \end{cases}
\end{equation}
где оценку корректности функции $f$ можно получить с помощью ошибок первого и второго рода.

Ошибкой I-го рода ($\alpha$-ошибкой, ложноположительным заключением, англ. false positive) будем называть ситуацию, при которой функция $f$ отнесёт экземпляр $t_i \in T$ к классу $y_1$ (<<аномальных>>), хотя фактически он является <<нормальным>>, то есть относится к классу $y_2$. Вероятность возникновения данного типа ошибки (также называемая \textit{уровнем значимости}) определяется соотношением (\ref{alpha_def}).

\begin{equation}\label{alpha_def}
    \alpha = P \Big\{ f(\overline{x_i}) = 1 \ \Big|\ t_i\ -\ \text{«нормальный» экземпляр} \Big\}
\end{equation}

Ошибкой II-го рода ($\beta$-ошибкой, ложноотрицательное заключением, англ. false negative) будем называть ситуацию, при которой функция $f$ отнесёт экземпляр $t_i \in T$ к классу $y_2$ (<<нормальных>>), хотя фактически он является <<аномальным>>, то есть относится к классу $y_1$. Вероятность возникновения данного типа ошибки по аналогии определяется соотношением (\ref{beta_def}).

\begin{equation}\label{beta_def}
    \beta = P \Big\{ f(\overline{x_i}) = -1 \ \Big|\ t_i\ -\ \text{«аномальный» экземпляр} \Big\}
\end{equation}
Также с этой величиной тесно связана другая, имеющая большое статистическое значение --- \textit{мощность критерия} $(1 - \beta)$. Таким образом, чем выше мощность критерия, тем меньше вероятность совершить ошибку второго рода.

Ошибки первого и второго рода взаимосвязаны между собой: при снижении уровня значимости увеличивается вероятность пропуска аномального трафика (уменьшается мощность критерия). В контексте текущей задачи, ошибка II-го рода может иметь более серьезные последствия, так как пропуск аномального трафика может привести к утечке данных или другим угрозам безопасности. В то же время, распространение ошибки I-го рода может негативно сказаться на пользовательском опыте администраторов и операторов разрабатываемой системы, поскольку это приводит к избыточной обработке и разбору ложноположительных инцидентов.

В результате задача, представленная в (\ref{task_formulation}),  заключается в минимизации вероятности ошибки второго рода при классификации, при этом на уровень значимости $\alpha$ накладывается ограничение значением порога $p$, которое определяет допустимый уровень ошибки I-го рода:

\begin{equation}\label{task_formulation}
    \begin{cases}
         \beta \rightarrow \min\limits_{
            \substack{
                \overline{x_i}\ :=\ \xi(t_i) \\
                f(\overline{x_i})
            }
        },
        \\
        \alpha \leq p.
    \end{cases}
\end{equation}

На основании исследований, представленных в работах \cite{Threshold-Adaptation}, \cite{Vasilyev-IS}, \cite{Detect-Anomalies-Deep-NN} принято решение установить пороговое значение ошибки первого рода на уровне $p = 0,05$, что позволит обеспечить баланс между безопасностью и удобством использования системы. Это значение будет использоваться для настройки алгоритмов классификации и оптимизации их работы. Также оно будет проверено результатами проводимых численных экспериментов.

